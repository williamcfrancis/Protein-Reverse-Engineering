{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kXK7zm6h86R",
        "outputId": "74295d16-d37d-4a2b-e8f1-c5d8fab65844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from difflib import SequenceMatcher\n",
        "import itertools"
      ],
      "metadata": {
        "id": "gf_zMegViEl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test  = np.load(\"/content/drive/MyDrive/X_test.npy\")\n",
        "Y_test  = np.load(\"/content/drive/MyDrive/Y_test.npy\")"
      ],
      "metadata": {
        "id": "AFADg0mPiFyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nucleotides = [\"A\", \"T\", \"C\", \"G\"]\n",
        "codons = [\"\".join(p) for p in itertools.product(nucleotides, repeat=3)]\n",
        "codon_vocab = {codon: idx for idx, codon in enumerate(codons)}\n",
        "codon_vocab[\"<PAD>\"] = 64\n",
        "codon_vocab[\"<SOS>\"] = 65\n",
        "codon_vocab[\"<EOS>\"] = 66\n",
        "id_to_codon = {v: k for k, v in codon_vocab.items()}"
      ],
      "metadata": {
        "id": "6T2AQtRziNYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProteinToDNATransformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder_embed = nn.Embedding(22, 128)  # 20 amino acids + PAD + SOS\n",
        "        self.decoder_embed = nn.Embedding(67, 128)  # 64 codons + PAD + SOS + EOS\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=128, nhead=8, num_encoder_layers=4,\n",
        "            num_decoder_layers=4, batch_first=True\n",
        "        )\n",
        "        self.fc_out = nn.Linear(128, 67)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_embed = self.encoder_embed(src)\n",
        "        tgt_embed = self.decoder_embed(tgt)\n",
        "        return self.fc_out(self.transformer(src_embed, tgt_embed))"
      ],
      "metadata": {
        "id": "jl2TuID8iOf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ProteinToDNATransformer()\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/models/best_transformer_with_sos.pt\", map_location=torch.device(\"cpu\")))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE9wLd0_iPxo",
        "outputId": "dfec9197-4f81-4e8a-ff23-e592cbae914e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ProteinToDNATransformer(\n",
              "  (encoder_embed): Embedding(22, 128)\n",
              "  (decoder_embed): Embedding(67, 128)\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-3): 4 x TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
              "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-3): 4 x TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
              "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (fc_out): Linear(in_features=128, out_features=67, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search_decode(model, src, beam_width=3, max_len=1160, start_token=65, pad_token=64):\n",
        "    device = next(model.parameters()).device\n",
        "    src = src.to(device)\n",
        "    sequences = [[torch.tensor([start_token], device=device), 0.0]]  # [sequence, score]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            all_candidates = []\n",
        "            for seq, score in sequences:\n",
        "                tgt_input = seq.unsqueeze(0)\n",
        "                out = model(src, tgt_input)\n",
        "                logits = out[:, -1, :]\n",
        "                probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
        "\n",
        "                topk_probs, topk_ids = torch.topk(probs, beam_width)\n",
        "\n",
        "                for i in range(beam_width):\n",
        "                    token = topk_ids[0][i].item()\n",
        "                    new_score = score + topk_probs[0][i].item()\n",
        "                    new_seq = torch.cat([seq, torch.tensor([token], device=device)])\n",
        "                    if token == pad_token:\n",
        "                        all_candidates.append([new_seq, new_score])\n",
        "                        continue\n",
        "                    all_candidates.append([new_seq, new_score])\n",
        "\n",
        "            sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
        "\n",
        "        return sequences[0][0]"
      ],
      "metadata": {
        "id": "hNuKDgtj72tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def codon_match(real, pred):\n",
        "    matches = sum(1 for a, b in zip(real, pred) if a == b)\n",
        "    return (matches / min(len(real), len(pred))) * 100\n"
      ],
      "metadata": {
        "id": "QpNHK0wCi7ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_similarity(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio() * 100"
      ],
      "metadata": {
        "id": "dAA3jmQJi-w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 2\n",
        "total_codon_match, total_similarity = 0, 0\n"
      ],
      "metadata": {
        "id": "2vJO4ZA2jAh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_samples):\n",
        "    src = torch.LongTensor(X_test[i]).unsqueeze(0)\n",
        "    pred_seq = beam_search_decode(model, src, beam_width=3)\n",
        "\n",
        "    real_codons = [id_to_codon[id] for id in Y_test[i] if id != 64]\n",
        "    pred_codons = [id_to_codon[id.item()] for id in pred_seq if id.item() != 64 and id.item() in id_to_codon]\n",
        "\n",
        "    cm = codon_match(real_codons, pred_codons)\n",
        "    sim = sequence_similarity(\"\".join(real_codons), \"\".join(pred_codons))\n",
        "\n",
        "    total_codon_match += cm\n",
        "    total_similarity += sim\n",
        "\n",
        "    print(f\"\\nSample {i+1}\")\n",
        "    print(\"Real:     \", \" \".join(real_codons[:15]))\n",
        "    print(\"Predicted:\", \" \".join(pred_codons[:15]))\n",
        "    print(f\"Codon Match: {cm:.2f}% | Sequence Similarity: {sim:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYve0Dy2jE3X",
        "outputId": "5cdfc566-9fc8-4aa4-810a-acf176b338ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample 1\n",
            "Real:      ATG GCC ATC CCT GCT TTT GGT TTA GGT ACT TTT AGG CTA AAG GAC\n",
            "Predicted: <SOS>\n",
            "Codon Match: 0.00% | Sequence Similarity: 0.00%\n",
            "\n",
            "Sample 2\n",
            "Real:      ATG CCA GGG AAT CGC CCA CAC TAT GGG CGG TGG CCG CAG CAC GAT\n",
            "Predicted: <SOS> ATG AAA AAA CGT TCG AAA AAA AAA CGT TCG AAA AAA AAA CGT\n",
            "Codon Match: 1.80% | Sequence Similarity: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dengichko ra!!"
      ],
      "metadata": {
        "id": "jsnN21SSjJy-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}